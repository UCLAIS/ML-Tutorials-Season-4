{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCLAIS Tutorial Series Challenge 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge you will be explore training and inferring using neural networks. You've already seen how to use classifiers in the previous challenge on premier league prediction. Now we will look at a regression task. Simply put, instead of trying to predict from a set of discrete classes, we are predicting a continuous value. In this case we will predict the alcohol content of wine based on a set of other chemical attribute.\n",
    "\n",
    "If you do not already have a DOXA account, you will want to [sign up](https://doxaai.com/sign-up) first before proceeding and then make sure you are enrolled on the [DOXA challenge page](https://doxaai.com/competition/uclais-2023-2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Workflow Reminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://miro.medium.com/max/1400/0*V0GyOt3LoDVfY7y5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall machine learning process covers a wide sequence of steps, so as you go through this notebook, try to keep in mind which stage are we dealing with and what we are trying to achieve. There are a lot of helpful resources online you can use, such as the excellent [scikit-learn documentation](https://scikit-learn.org/stable/getting_started.html). You are also more than welcome to ask questions in the [DOXA Community Discord server](https://discord.gg/MUvbQ3UYcf)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Useful Packages\n",
    "\n",
    "To get started, we will install a number of common machine learning packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas matplotlib seaborn scikit-learn ipympl\n",
    "%pip install -U doxa-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gives live loss plots -- recommended\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now also make sure we're using out computer GPU for best performance. Make sure it says \"Using cuda device\" below. If not, go to \"Runtime\" -> \"Change runtime type\" in google colab and change to GPU. This will make model training a lot faster!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the data as a panda's dataframe. We use the [wine quality dataset](https://archive.ics.uci.edu/dataset/186/wine+quality). The goal of this challenge will be to use a neural network to predict the alcohol content of a wine given its other properties. The properties are based on physicochemical tests, and there are 10 features in total. The target variable is the alcohol content, which is a continuous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training dataset\n",
    "train_df_original = pd.read_csv(\n",
    "    \"./data/train.csv\"\n",
    ")  # Change the path accordingly\n",
    "\n",
    "# Import the testing dataset\n",
    "test_df = pd.read_csv(\n",
    "    \"./data/test.csv\"\n",
    ")  # Change the path accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then make an in-memory copy of the training set to manipulate\n",
    "# and process while leaving the original intact as we experiment\n",
    "df = train_df_original.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "Before we start to train our Machine Learning model, it is important to have a look and understand first the dataset that we will be using. This will provide some insights onto which model, model hyperparameter, and loss function are suitable for the problem we are dealing with. The [first doxa challenge](https://doxaai.com/competition/uclais-2023-1) has good content on data understanding. Check that out if you want to explore further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the first five rows of the data\n",
    "\n",
    "# Hint: use the '.head()' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the number of rows and columns in the dataset \n",
    "\n",
    "# Hint: use '.shape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the summary statistics for the dataset\n",
    "\n",
    "# Hint: use '.describe()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we preprocess the data to make the data suitable for training. We will first split the data into training and validation sets. Feel free to add new cells as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into X and y variables. X are the features and y is the target variable. we wand to predict. \n",
    "# We are trying to predict the alcohol content given the other variables. \n",
    "X_train = df.drop('alcohol', axis=1)\n",
    "y_train = df['alcohol']\n",
    "\n",
    "# We done covert the Matrix X and vector y in numpy arrays.\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add your own data pre-processing steps here. (hint: it might be worth looking at normalizing the data to make training easier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the architecture of our model. Remember the more complex your model architecture, the more complex your data will be able to fit. However, this also means that your model will be more prone to overfitting. So be careful! You can also look at other ways of reducing overfitting such as regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input_features, num_hidden_neurons = X_train.shape[1], 10\n",
    "model = nn.Sequential(\n",
    "    # TODO: add layers to our model\n",
    "\n",
    "    # Note: remember that we are trying to predict a continuous variable.\n",
    "    # Our output layer should have only one neuron, and our input layer should be the number of columns in X.\n",
    "\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model = model.cuda() if torch.cuda.is_available() else model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our Model\n",
    "\n",
    "Now it's finally time to train our model! Make sure to use the training set to avoid overfittng! First, we define the hyperparameter. Feel free to experiment with those!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change 'None' with values you think are appropriate. Experiment with different values to see what works best!\n",
    "learning_rate = None\n",
    "batch_size = None\n",
    "num_epochs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your loss function below. Options are given in the [documentation](https://pytorch.org/docs/stable/nn.functional.html#loss-functions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace 'None' with your loss function.\n",
    "\n",
    "# Hint: we are trying to predict a continuous variable.\n",
    "\n",
    "def loss_fun(pred, target):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also define our optimizer. Look at the [documentation](https://pytorch.org/docs/stable/optim.html#algorithms) for a list of optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace 'None' with your optimizer.\n",
    "optim = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we set up our model for training and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep track of losses\n",
    "plotlosses = PlotLosses()\n",
    "\n",
    "# Convert our training data to tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
    "\n",
    "# Change model to training mode\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(num_epochs):\n",
    "    # TODO: add the code to train your model. (hint: use plotlosses to see the live loss plot)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing your DOXA Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X_test = test_df.to_numpy()\n",
    "\n",
    "# Pass our data through our neural network\n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    predictions = model(torch.from_numpy(X_test).float().to(device)).numpy().squeeze()\n",
    "\n",
    "assert predictions.shape == (1300,) \n",
    "\n",
    "# Take a look at the first 20 predictions\n",
    "predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"submission\", exist_ok=True)\n",
    "\n",
    "with open(\"submission/y.txt\", \"w\") as f:\n",
    "    f.writelines([f\"{prediction}\\n\" for prediction in predictions])\n",
    "\n",
    "with open(\"submission/doxa.yaml\", \"w\") as f:\n",
    "    f.write(\n",
    "        \"competition: uclais-2023-2\\nenvironment: cpu\\nlanguage: python\\nentrypoint: run.py\"\n",
    "    )\n",
    "\n",
    "with open(\"submission/run.py\", \"w\") as f:\n",
    "    f.write(\n",
    "        \"\"\"import os\n",
    "\n",
    "with open('y.txt', 'r') as f:\n",
    "    with open(os.environ[\"DOXA_STREAMS\"] + \"/out\", \"w\") as g:\n",
    "        g.write(f.read().strip())\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to DOXA\n",
    "\n",
    "Before you can submit to DOXA, you must first ensure that you are enrolled for the challenge on the DOXA website. Visit [the challenge page](https://doxaai.com/competition/uclais-1) and click \"Enrol\" in the top-right corner if you have not done so already.\n",
    "\n",
    "You can then log in using the DOXA CLI by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!doxa login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can submit your results to DOXA by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!doxa upload submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wooo! 🥳 You have (probably) just uploaded your predictions to DOXA &ndash; well done! Take a moment to see how you have done on the [scoreboard](https://doxaai.com/competition/uclais-2023-2/scoreboard)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
